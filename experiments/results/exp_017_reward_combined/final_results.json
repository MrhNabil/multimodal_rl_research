{
  "experiment_name": "exp_017_reward_combined",
  "timestamp": "2025-12-14T01:36:06.295270",
  "method": "rl",
  "accuracy": 0.0,
  "best_val_accuracy": 0.0,
  "batch_size": 16,
  "max_steps": 50,
  "learning_rate": 0.0001,
  "eval_every": 25,
  "save_every": 50,
  "reward_type": "combined",
  "baseline_type": "moving_avg",
  "temperature": 1.0,
  "entropy_coef": 0.01,
  "seed": 42
}